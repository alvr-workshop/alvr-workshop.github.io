<!DOCTYPE html>
    <meta charset="UTF-8">
  <title>ALVR 2020</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  </head>
  <body>

  <section class="page-header" style="width:900px;margin: auto; background-color:white">

      <h1 class="project-name">ALVR 2020</h1>
      <h4 class="project-tagline">First Workshop on Advances in Language and Vision Research<div style="float: right; clear: right;"><b>Date:</b> July 9, 2020</div> 
<br>&nbsp;&nbsp;&nbsp;&nbsp;<div style="float: right; clear: right;"><b>Room:</b> TBD</div> 
</h4>
<!-- <br> -->
<h4  class="project-tagline">In conjunction with the 2020 Annual Conference of the Association for Computational Linguistics <a href="https://acl2020.org">(ACL 2020)</a></h4>
<br>

  </section>

  <section style="width:900px;margin: auto;  background-color:white">
  <!-- Static navbar -->
      <nav class="navbar navbar-default">
        <div class="container-fluid">
          <div class="navbar-header">
            <butfton type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

          </div>
          <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li class="active"><a href="#invitedSpeakers">Speakers</a></li>
	      <li><a href="#schedule">Schedule</a></li>
              <li><a href="#proceedings">Proceedings</a></a></li>
              <li><a href="#overview">Overview & CFP</a></a></li>
              <li><a href="#submission-info">Submission</a></li>
         <li><a href="#important-dates">Important Dates</a></li>
              <li><a href="#organizers">Organizers & PC</a></li>
         <!-- <li><a href="#pastworkshops">Past Workshops</a></li> -->
         </ul>
            </div><!--/.nav-collapse -->
        </div><!--/.container-fluid -->
      </nav>

   </section>

   <section class="main-content" style="width:900px;margin: auto;  background-color:white">


<a id="invitedSpeakers" class="anchor" href="#invitedSpeakers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Invited Speakers</h2>

<font size=3>

<ul>
<li><a href="https://yoavartzi.com/">Yoav Artzi</a>, Cornell</li>
<li><a href="http://www.cse.msu.edu/~jchai/">Joyce Chai</a>, University of Michigan</li>
<li><a href="https://www.microsoft.com/en-us/research/people/jingjl/">JJ (Jingjing) Liu</a>, Microsoft</li>
<li><a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a>, CMU</li>
<li><a href="http://eilab.gatech.edu/mark-riedl">Mark Riedl</a>, Georgia Tech</li>
<li><a href="http://www.imperial.ac.uk/people/l.specia">Lucia Specia</a>, Imperial College London</li>
<li><a href="http://zhouyu.cs.ucdavis.edu/">Zhou Yu</a>, UC Davis</li>
<!-- <li><a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a>, University of Toronto (<b>TBD</b>)</li>  -->
<!-- <li><a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a>, Stanford (<b>TBD</b>)</li> -->
<!-- <li><a href="https://nlp.stanford.edu/manning/">Christopher Manning</a>, Stanford (<b>TBD</b>)</li> -->
</ul>
</font>

<a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Schedule</h2>
<table class="table" style="width:100%">
      <tr class="info">
        <td>8:30-8:40</td>
        <td><strong>Opening remarks</strong></td> 
        <td>Workshop Organizers</td>
      </tr>
  
      <tr class="success">
        <td>8:40-9:15</td>
        <td><strong>Invited Talk </strong></td> 
        <td> </td>
      </tr>

      <tr class="success">
        <td>9:15-9:50</td>
        <td><strong>Invited Talk </strong></td> 
        <td></td>
      </tr>

      <tr class="info">
        <td>9:50-10:10</td>
        <td><strong>VATEX Challenge</strong></td>                      
        <td></td>
      </tr>

      <tr class="info">
        <td>10:10-10:20</td>
        <td><strong>Challenge Talk [runner up]</strong></td> 
        <td> </td>
      </tr>

      <tr class="info">
        <td>10:20-10:30</td>
        <td><strong>Challenge Talk [winner]</strong></td> 
        <td> </td>
      </tr>

      <tr>
        <td>10:30-11:00</td>
        <td><strong>Coffee Break and Poster Session</strong></td> 
        <td> </td>
      </tr>


      <tr class="success">
        <td>11:00-11:35</td>
        <td><strong>Invited Talk </strong></td>
        <td></td>
      </tr>

      <tr class="success">
        <td>11:35-12:10</td>
        <td><strong>Invited Talk </strong></td>
        <td></td>
      </tr>

      <tr>
        <td>12:10-2:00</td>
        <td><strong>Lunch</strong></td> 
        <td> </td>
      </tr>

      <tr class="success">
        <td>2:00-2:35</td>
        <td><strong>Invited Talk </strong></td>
        <td></td>
      </tr>

      <tr class="success">
        <td>2:35-3:00</td>
        <td><strong>Invited Talk </strong></td>
        <td></td>
      </tr>

      <tr class="info">
        <td>3:10-3:30</td>
        <td><strong>Poster Highlights</strong></td>
        <td> </td>
      </tr>

      <tr>
        <td>3:30-4:00</td>
        <td><strong>Coffee Break and Poster Session</strong></td>
        <td></td>
      </tr>
	
      <tr class="success">
        <td>4:00-4:35</td>
        <td><strong>Invited Talk</strong>
        </td>
        <td></td>
      </tr>

      <tr class="success">
        <td>4:35-5:10</td>
        <td><strong>Invited Talk</strong>
        </td>
        <td></td>
      </tr>

      <tr class="info">
        <td>5:10-5:40</td>
        <td><strong>Panel Discussion</strong></td>
        <td></td>
      </tr>

      

    </table>

<!-- <font size=3>
<ul>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1607/">SpatialNet: A Declarative Resource for Spatial Relations</a> <b>(Best Paper)</b><br><i><font size=2>Morgan Ulinski, Bob Coyne and Julia Hirschberg</font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1605/">Multi-modal Discriminative Model for Vision-and-Language Navigation </a><b>(Best Paper)</b><br><i><font size=2>Haoshuo Huang, Vihan Jain, Harsh Mehta, Jason Baldridge and Eugene Ie </font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1601/">Corpus of Multimodal Interaction for collaborative planning</a><br><i><font size=2>Miltiadis Marios Katsakioris, Helen Hastie, Ioannis Konstas and Atanas Laskov </font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1602/">¿Es un plátano? Exploring the Application of a Physically Grounded Language Acquisition System to Spanish</a><br><i><font size=2>Caroline Kery, Cynthia Matuszek and Francis Ferraro</font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1604/">Learning from Implicit Information in Natural Language Instructions for Robotic Manipulations</a><br><i><font size=2>Ozan Arkan Can, Pedro Zuidberg Dos Martires, Andreas Persson, Julian Gaal, Amy Loutfi, Luc De Raedt, Deniz Yuret and Alessandro Saffiotti </font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1606/">Semantic Spatial Representation: a unique representation of an environment based on an ontology for robotic applications</a><br><i><font size=2>Guillaume Sarthou, Aurélie Clodic and Rachid Alami</font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1603/">From Virtual to Real: A Framework for Verbal Interaction with Robots</a><br><i><font size=2>Eugene Joseph</font></i></li>
<li><a href="https://aclweb.org/anthology/papers/W/W19/W19-1608/">What a neural language model tells us about spatial relations</a><br><i><font size=2>Mehdi Ghanimifard and Simon Dobnik</font></i></li>
</ul>
</font>

<br><font size=5><b>Cross Submissions</b></font>
<font size=3>
<ul>
<li><a href="nonarchival/pillai.pdf" target="_blank">Deep Learning for Category-Free Grounded Language Acquisition</a><br><i><font size=2>Nisha Pillai, Francis Ferraro and Cynthia Matuszek</font></i></li>
<li><a href="https://arxiv.org/abs/1905.04655" target="_blank">Improving Natural Language Interaction with Robots Using Advice</a><br><i><font size=2>Nikhil Mehta and Dan Goldwasser</font></i></li>
<li><a href="https://arxiv.org/abs/1904.01650" target="_blank">Improving Robot Success Detection using Static Object Data</a><br><i><font size=2>Rosario Scalise, Jesse Thomason, Yonatan Bisk and Siddhartha Srinivasa</font></i></li>
<li><a href="https://arxiv.org/abs/1904.07165" target="_blank">Learning to Generate Unambiguous Spatial Referring Expressions for Real-World Environments</a><br><i><font size=2>Fethiye Irmak Dogan, Sinan Kalkan and Iolanda Leite</font></i></li>
<li>Learning to Ground Language to Temporal Logical Form<br><i><font size=2>Roma Patel, Stefanie Tellex and Ellie Pavlick</font></i></li>
<li><a href="https://arxiv.org/abs/1904.04195" target="_blank">Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout</a><br><i><font size=2>Hao Tan, Licheng Yu and Mohit Bansal</font></i></li>
<li>Learning to Parse Grounded Language using Reservoir Computing<br><i><font size=2>Xavier Hinaut and Michael Spranger</font></i></li>
<li><a href="https://arxiv.org/abs/1811.10092">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation</a><br><i><font size=2>Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang and Lei Zhang</font></i></li>
<li><a href="nonarchival/multirobot_dialog.pdf" target="_blank">A Research Platform for Multi-Robot Dialogue with Humans</a><br><i><font size=2>Matthew Marge, Stephen Nogar, Cory Hayes, Stephanie M. Lukin, Jesse Bloecker, Eric Holder and Clare Voss</font></i></li>
<li>From Spatial Relations to Spatial Configurations<br><i><font size=2>Soham Dan, Parisa Kordjamshidi, Julia Bonn, Archna Bhatia, Martha Palmer and Dan Roth</font></i></li>
<li><a href="https://arxiv.org/abs/1903.02547">Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation</a><br><i><font size=2>Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi and Siddhartha Srinivasa</font></i></li>
<li><a href="https://arxiv.org/abs/1904.05521v2" target="_blank">UniVSE: Robust Visual Semantic Embeddings via Structured Semantic Representations</a><br><i><font size=2>Hao Wu, Jiayuan Mao, Yufeng Zhang, Yuning Jiang, Lei Li, Weiwei Sun and Wei-Ying Ma</font></i></li>
</ul>
</font> -->





<h2 id="overview" class="anchor" aria-hidden="True" href="#overview">Overview and Call For Papers</h2>

<p>
Language and vision research has attracted great attention from both natural language processing (NLP)
and computer vision (CV) researchers, which is gradually shifting from passive perception, templated language and synthetic imagery/environments to active perception, natural language and photo-realistic simulation (or even real world). Thus far, few workshops on language and vision research have been organized
by groups from the NLP community. We propose the <b>first workshop on Advances in Language and Vision Research (ALVR)</b> in order to promote the frontier of language and vision research and bring interested
researchers together to discuss how to best tackle and solve real-world problems in this area.</p>

<p>This workshop covers (but is not limited to) the following topics: </p>

<ul>
<li> New tasks and datasets that provide real-world solutions in the intersection of NLP and CV; </li>
<li> Language-guided interaction with the real world, such as navigation via instruction following or dialogue; </li>
<li> External knowledge integration in visual and language understanding; </li>
<li> Visually grounded multilingual study, for example multimodal machine translation; </li>
<li> Shortcoming of existing language and vision tasks and datasets; </li>
<li> Benefits of using multimodal learning in downstream NLP tasks; </li>
<li> Self-supervised representation learning in language and vision; </li>
<li> Transfer learning (including few/zero-shot learning) and domain adaptation; </li>
<li> Cross-modal learning beyond image understanding, such as videos and audios; </li>
<li> Multidisciplinary study that may involve linguistics, cognitive science, robotics, etc. </li>
</ul>

<p>In addition, we will also hold the <b>first Video-guided Machine Translation Challenge</b>, which we refer
to as VATEX Translation Challenge 2020. The challenge aims to initiate studies and benchmark progress towards
models that can translate the source language into the target language with the assistance of spatiotemporal
context in videos. This challenge is based on the recently released large-scale multilingual video description dataset, VATEX. The VATEX dataset contains over 41,250
videos and 825,000 high-quality captions in both English and Chinese, half of which are English-Chinese
translation pairs. Winners will be announced and awarded in the workshop. </p>

<br>
<a id="submission-info" class="anchor" href="#submission-info" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<!--
<h4>Camera-ready details</h4>
Archival track camera-ready papers should be prepared with NAACL style, either 9 pages without references (long papers) or up to 5 pages without references (short papers). Please make submissions via softconf <a href="https://www.softconf.com/naacl2019/splu">here</a> by <b>April 8</b>.
<br/><br/>
Non-archival track camera-ready papers should be uploaded online (e.g., to arxiv), and links to those camera-ready copies sent to the organizing committee at splu-robonlp-2019@googlegroups.com
<br/><br/>
-->

<h4>Submission details</h4>
<h5>Archival Track</h5>
<p>The archival track follows the ACL short paper format. Submissions to the archival track may consist of up to 4 pages of content (excluding references) in ACL format (style sheets are available below), plus unlimited references. Accepted papers will be given 5 content pages for camera-ready version. Authors are encouraged to use this additional page to address reviewers’ comments in their final versions. The accepted papers to the archival track will be included in the ACL 2020 Workshop proceedings. The archival track does not accept double submissions, e.g., no previously published papers or concurrent submissions to other conferences or workshops.</p>

<p>The format of submitted papers to the archival track must follow the ACL Author Guidelines.
Style sheets (Latex, Word) are available <a href="http://acl2020.org/downloads/acl2020-templates.zip" target="_blank">here</a>.
And the Overleaf template is also available <a href="https://www.overleaf.com/latex/templates/acl-2020-proceedings-template/zsrkcwjptpcd" target="_blank">here</a>.</p>

<h5>Non-archival Track</h5>
<p>The workshop also includes a non-archival track to allow submission of previously published papers and double submission to ALVR and other conferences or journals. Accepted non-archival papers can still be presented as posters at the workshop.
There are no formatting or page restrictions for non-archival submissions. The accepted papers to the non-archival track will be displayed on the workshop website, but will NOT be included in the ACL 2020 Workshop proceedings or otherwise archived.</p>

</center>


<!-- <h4><a href="https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy">ACL Anti-Harassment Policy</a></h4> -->

 <a id="important-dates" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Important Dates</h2>
<ul>
  <li><b>Submission Deadline: April 6, 2020</b> (11:59pm Anywhere on Earth time, UTC-12)</li>
  <li>Notification: May 4, 2020</li>
  <li>Camera Ready deadline: May 18, 2020</li>
  <li>Workshop Day: July 9, 2020</li>
</ul>


<a id="proceedings" class="anchor" href="#proceedings" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Proceedings</h2>
TBD


<a id="organizers" class="anchor" href="#organizers" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<h2>Organizers and PC</h2>
<div class="container" style="width:900px;margin: auto;">
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        Organizers
      </h4>
    </div>
    <div id="collapse1">
      <div class="panel-body">
          <table cellspacing="0" cellpadding="0" style="width:100%">
         
          <tr>
          <td><li><a href="https://sites.cs.ucsb.edu/~xwang/"> Xin Wang</a></td>
          <td>UC Santa Barbara</li></td>
          <td>xwang@cs.ucsb.edu</td>
          </tr>
          
          <tr>
          <td><li><a href="https://jessethomason.com/">Jesse Thomason</a></td>
          <td>University of Washington</li></td>
          <td>thomason.jesse@gmail.com</td>
          </tr>

          <tr>
          <td><li><a href="http://ronghanghu.com/">Ronghang Hu</a></td>
          <td>UC Berkeley</li></td>
          <td>ronghang@berkeley.edu</td>
          </tr>

          <tr>
          <td><li><a href="http://xinleic.xyz/">Xinlei Chen</a></td>
          <td>Facebook AI Research</li></td>
          <td>xinleic@fb.com</td>
          </tr>

          <tr>
          <td><li><a href="https://panderson.me/">Peter Anderson</a></td>
          <td>Georgia Tech</li></td>
          <td>peter.anderson@gatech.edu</td>
          </tr>

          <tr>
          <td><li><a href="http://www.qi-wu.me/">Qi Wu</a></td>
          <td>Adelaide University</li></td>
          <td>qi.wu01@adelaide.edu.au</td>
          </tr>
          
          <tr>                         
          <td><li><a href="https://www.microsoft.com/en-us/research/people/aslicel/">Asli Celikyilmaz</a></td>
          <td>Microsoft Research</li></td>
          <td>asli.ca@live.com</td>
          </tr>

          <tr>
          <td><li><a href="http://www.jasonbaldridge.com/">Jason Baldridge</a></td>
          <td>Google Research</li></td>
          <td>jasonbaldridge@google.com</td>
          </tr>

          <tr>
          <td><li><a href="https://sites.cs.ucsb.edu/~william/index.html">William Yang Wang</a></td>
          <td>UC Santa Barbara</li></td>
          <td>william@cs.ucsb.edu</td>
          </tr>
          
          </table>

      </div>
    </div>
    <p style="margin-left: 20px;">Contact the Organizing Committee: <a href="mailto:alvr-2020@googlegroups.com">alvr-2020@googlegroups.com</a></p>
  </div>

  <!-- Contact Organizing Committee:<a href="mailto:splu-robonlp-2019@googlegroups.com?Subject=SpLU-RoboNLP" target="_top"> splu-robonlp-2019@googlegroups.com </a> </p> -->
  
  <div class="panel panel-default">
    <div class="panel-heading">
      <h4 class="panel-title">
        Program Committee
      </h4>
    </div>
    <div id="collapse2">
      <div class="panel-body">
        <table cellspacing="0" cellpadding="0" style="width:65%">
	<tr><td><li>Jacob Andreas</td> <td>MIT</td></li> <td> </td></tr>
        <tr><td><li>Angel Chang</td><td>Simon Fraser Univeristy</li></td> <td> </td></tr>
        <tr><td><li>Devendra Chaplot</td><td>CMU</li></td> <td> </td></tr>
        <tr><td><li>Abhishek Das</td><td>Georgia Tech</li></td> <td> </td></tr>
        <tr><td><li>Daniel Fried </td><td>UC Berkeley</li></td> <td> </td></tr>
        <tr><td><li>Zhe Gan</td><td>Microsoft</li></td> <td> </td></tr>
        <tr><td><li>Christopher Kanan</td><td>Rochester Institute of Technology</td></li> <td> </td></tr>
        <tr><td><li>Jiasen Lu</td><td>Georgia Tech</li></td> <td> </td></tr>
        <tr><td><li>Ray Mooney</td><td>University of Texas, Austin </td></li> <td> </td></tr>
        <tr><td><li>Khanh Nguyen</td><td>University of Maryland </td></li> <td> </td></
tr>
        <tr><td><li>Aishwarya Padmakumar</td> <td>University of Texas, Austin </td></li> <td> </td></tr>
	<tr><td><li>Hamid Palangi</td> <td>Microsoft Research</td></li> <td> </td></tr>
        <tr><td><li>Alessandro Suglia</td><td>Heriot-Watt University</td></li> <td> </td></tr>
        </table>
      </div>
      <p style="color: #8C1515; margin-left: 20px;">If you are interested in taking a more active part in the workshop, apply to <a href="https://forms.gle/voyxjQLFb8duYM5e7">join the program committee</a>.</p>
    </div>
  </div>
</div>


<!-- <a id="pastworkshops" class="anchor" href="#pastworkshops" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<h2>Past Workshops</h2>

<p>
<a href="https://spatial-language.github.io/old_SpLU_workshops/SpLU_2018/"> SpLU 2018</a>
</p>
<p><a href=" https://robo-nlp.github.io/2017_index.html"> Robo-NLP 2017</a>
</p>

<h2>Sponsors</h2>
<p><img src="ms_logo_cam.gif" width="25%"></p>
<p><img src="google_logo.png" width="25%"></p>
</section> -->

</body>
</html>
