<!-- FlatFy Theme - Andrea Galanti /-->
<!doctype html>
<!--[if lt IE 7]> <html class="no-js ie6 oldie" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js ie7 oldie" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js ie8 oldie" lang="en"> <![endif]-->
<!--[if IE 9]>    <html class="no-js ie9" lang="en"> <![endif]-->
<!--[if gt IE 9]><!--> <html> <!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0">
    <meta name="description" content="Workshop on Advances in Language and Vision Research ">
    <meta name="author" content="">

    <title>ALVR 2021</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Google Web Font -->
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Arvo:400,700' rel='stylesheet' type='text/css'>

    <!-- Custom CSS-->
    <link href="css/general.css" rel="stylesheet">

    <!-- Owl-Carousel -->
    <link href="css/custom.css" rel="stylesheet">
    <link href="css/owl.carousel.css" rel="stylesheet">
    <link href="css/owl.theme.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <link href="css/animate.css" rel="stylesheet">

    <!-- Magnific Popup core CSS file -->
    <link rel="stylesheet" href="css/magnific-popup.css">

    <script src="js/modernizr-2.8.3.min.js"></script> <!-- Modernizr /-->
    <!--[if IE 9]>
    <script src="js/PIE_IE9.js"></script>
    <![endif]-->
    <!--[if lt IE 9]>
    <script src="js/PIE_IE678.js"></script>
    <![endif]-->

    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <![endif]-->

</head>

<body id="home">

<!-- Preloader -->
<!--
<div id="preloader">
    <div id="status"></div>
</div>
-->

<!-- FullScreen -->
<div class="intro-header">
    <div class="col-xs-12 text-center">
        <div style="background-color: rgba(0,0,0,0.5)">
        <h1 class="h1_home wow " data-wow-delay="0.4s" style="color:white; text-shadow: 0 0 8px black;">2<sup>nd</sup> Workshop on Advances in Language and Vision Research (ALVR)</h1>
        <h3 class="h3_home wow " data-wow-delay="0.6s" style="color:white; text-shadow: -1px 0 black, 0 1px black, 1px 0 black, 0 -1px black, 2px 2px 4px black">
            In conjunction with <a style="color:white" href="https://2021.naacl.org/" target="_blank"><b>NAACL 2021</b></a> <br>
            June 11<sup>st</sup> 2021 (Full Day) <br>
            Location: Virtual
        </h3>
        </div>
        <!--
        <h3 class="h3_home wow " data-wow-delay="0.6s" style="color:black; background-color:rgba(255,255,255,0.5); text-shadow: -1px 0 black, 0 1px black, 1px 0 black, 0 -1px black, 2px 2px 4px black">
            In conjunction with <a style="color:black" href="https://2021.naacl.org/" target="_blank"><b>NAACL 2021</b></a> <br>
            June 11<sup>st</sup> 2021 (Full Day) <br>
            Location: Mexico City, Mexico
        </h3>
        -->
        <!--ul class="list-inline intro-social-buttons">
            <li><a href="https://twitter.com/galantiandrea" class="btn  btn-lg mybutton_cyano wow " data-wow-delay="0.8s"><span class="network-name">Twitter</span></a>
            </li>
            <li id="download" ><a href="#downloadlink" class="btn  btn-lg mybutton_standard wow swing wow " data-wow-delay="1.2s"><span class="network-name">Free Download</span></a>
            </li>
        </ul-->
    </div>
    <!-- /.container -->
    <div class="col-xs-12 text-center abcen wow ">
        <div class="button_down ">
            <a class="imgcircle wow bounceInUp" data-wow-duration="1.5s"  href="#scope"> <img class="img_scroll" src="img/icon/circle.png" alt=""> </a>
        </div>
    </div>
    <span class="intro-caption">Photo by <a href="https://unsplash.com/@manuel_arroyo25">Manuel Arroyo</a> on <a href="http://www.unsplash.com">Unsplash</a> </span>
</div>

<!-- NavBar-->
<nav class="navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#home">ALVR 2021</a>
        </div>

        <div class="collapse navbar-collapse navbar-right navbar-ex1-collapse">
            <ul class="nav navbar-nav">

                <li class="menuItem"><a href="#scope">Home</a></li>
                <li class="menuItem"><a href="#dates">Dates</a></li>
                <li class="menuItem"><a href="#submit">Submission</a></li>
                <!-- <li class="menuItem"><a href="#proceedings">Proceedings</a></li> -->
                <li class="menuItem"><a href="#accepted-papers">Accepted Papers</a></li>
                <li class="menuItem"><a href="#program">Program</a></li>
                <li class="menuItem"><a href="#invited">Invited Speakers</a></li>
                <li class="menuItem"><a href="#organizers">Organizers</a></li>
                <!-- <li class="menuItem"><a href="#sponsors">Sponsor</a></li>					 -->
                <!-- <li class="menuItem"><a href="#contacts">Contact</a></li> -->
                <li class="menuItem"><a href="2020/index.html">ALVR 2020</a></li>
            </ul>
        </div>

    </div>
</nav>

<!-- Scope -->
<div id ="scope" class="content-section-a" style="border-top: 0">

    <div class="container">

        <div class="row">

            <!--div class="col-sm-6 pull-right wow ">
                <img class="img-responsive " src="img/ipad.png" alt="">
            </div-->
            <!--<img  class="img-responsive"  style="width: 20vw"  src="img/cvpr_logo.png" alt="">
            <img  class="img-responsive"  style="width: 20vw"  src="img/cvf.jpg" alt="">
            <img  class="img-responsive"  style="width: 10vw"  src="img/organizer/vgis.png" alt="">  -->
            <div class="wow " data-animation-delay="200">
                <!--<h3 class="section-heading">ACL 2020 Workshop on Advances in Language and Vision Research</h3>-->
                <h3 class="section-heading">2<sup>nd</sup> Workshop on Advances in Language and Vision Research</h3>

                <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
                <p>
                    Language and vision research has attracted great attention from both natural language processing (NLP) and computer vision (CV) researchers. Gradually, this area is shifting from passive perception, templated language, and synthetic imagery/environments to active perception, natural language, and photo-realistic simulation or real world deployment. Thus far, few workshops on language and vision research have been organized by groups from the NLP community. We are organizing <b>the second workshop on Advances in Language and Vision Research (ALVR)</b> in order to promote the frontier of language and vision research and to bring interested researchers together to discuss how to best tackle and solve real-world problems in this area.<br/><br/>
                    This workshop covers (but is not limited to) the following topics: <br/>
                <ul>
                    <li> New tasks and datasets that provide real-world solutions in the intersection of NLP and CV; </li>
                    <li> Language-guided interaction with the real world, such as navigation via instruction following or dialogue; </li>
                    <li> External knowledge integration in visual and language understanding; </li>
                    <li> Visually grounded multilingual study, for example multimodal machine translation; </li>
                    <li> Shortcomings of existing language and vision tasks and datasets; </li>
                    <li> Benefits of using multimodal learning in downstream NLP tasks; </li>
                    <li> Self-supervised representation learning in language and vision; </li>
                    <li> Transfer learning (including few/zero-shot learning) and domain adaptation; </li>
                    <li> Cross-modal learning beyond image understanding, such as video and audio; </li>
                    <li> Multidisciplinary study that may involve linguistics, cognitive science, robotics, etc. </li>
                </ul>
                </p>

                <!-- <a id="important-dates" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a>_..

                 <!--p><a class="btn btn-embossed btn-primary" href="#" role="button">View Details</a>
                 <a class="btn btn-embossed btn-info" href="#" role="button">Visit Website</a></p-->
            </div>
        </div>
    </div>
    <!-- /.container -->
</div>

<div id ="dates" class="content-section-b" style="border-top: 0">
    <div class="container">
        <div class="row">
            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading">Important Dates</h3>
                <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
                <ul>
                    <!--<del><li><b>SubmissionÂ Deadline (extended): April 16, 2020</b> (11:59pm Anywhere on Earth time, UTC-12)</li></del>
                    <del><li>Notification: May 11, 2020</li></del>
                    <del><li>Camera Ready deadline: May 21, 2020 (11:59pm Anywhere on Earth time, UTC-12)</li></del>-->
                    <li>Archival track:</li>
                    <ul>
                      <li><s>Paper Submission Due Date: March 22, 2021</s></li>
                      <li><s>Notification of acceptance: April 15, 2021</s></li>
                        <li><s>Camera-ready papers due: April 26, 2021</s></li>
                    </ul>
                    <li>Non-archival track:</li>
                    <ul>
                        <li><s>Paper Submission Due Date: April 30, 2021</s></li>
                        <li><s>Notification of acceptance: May 14, 2021</s></li>
                        <li>Camera-ready papers due: May 24, 2021</li>
                    </ul>
                    <li>Workshop Date: June 11, 2021</li>
                </ul>
            </div>
        </div>
    </div>
</div> <!-- /dates -->

<!-- Call for Papers -->
<div id ="submit" class="content-section-b">

    <div class="container">

        <div class="row">

            <!--div class="col-sm-6 pull-right wow ">
                <img class="img-responsive " src="img/ipad.png" alt="">
            </div-->

            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading">Submission</h3>
                <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->

                <p>The workshop includes an archival and a non-archival track on topics related to language-and-vision research. For both tracks, the reviewing process is single-blind. That is, the reviewer will know the authors but not the other way around. Submission is electronic, using the Softconf START conference management system. The submission site will be available at <a href="https://www.softconf.com/naacl2021/alvr2021" style="color:orange">https://www.softconf.com/naacl2021/alvr2021</a>.</p>
                <!--<p class="lead"  style="text-align:justify">If you are interested in taking a more active part in the workshop, we also encourage you to apply to join the program committee and participate in reviewing submissions following this link: TBD. Qualified reviewers will be selected based on the prior reviewing experience and publication records.</p> -->

                <h4 class="section-heading">Archival Track</h4>
                <p>
                    The archival track follows the NAACL short paper format
                    (<a href="https://2021.naacl.org/calls/papers/#short-papers" style="color:orange">https://2021.naacl.org/calls/papers/#short-papers</a>).
                    Submissions to the archival track may consist of up to 4 pages of content (excluding references) in
                    NAACL format (style sheets are available below), plus extra space for an optional ethics/broader
                    impact statement and unlimited references. Accepted papers will be given 5 content pages for the
                    camera-ready version. Authors are encouraged to use this additional page to address reviewersâ
                    comments in their final versions. The accepted papers to the archival track will be included in the
                    NAACL 2021 Workshop Proceedings. The archival track does not accept double submissions, e.g., no
                    previously published papers or concurrent submissions to other conferences or workshops.
                </p>
                <p>
                    The format of submitted papers to the archival track must follow the NAACL Author Guidelines.
                    Style sheets (Latex, Word) are available here:
                    <a href="https://2021.naacl.org/calls/style-and-formatting/" style="color:orange">https://2021.naacl.org/calls/style-and-formatting/</a>
                </p>

                <h4 class="section-heading">Non-archival Track</h4>
                <p>
                    The workshop also includes a non-archival track to allow submission of previously published papers and
                    double submission to ALVR and other conferences or journals. Accepted non-archival papers can still be
                    presented as posters at the workshop.
                </p>

                <p>
                    There are no formatting or page restrictions for non-archival submissions. The accepted papers to the
                    non-archival track will be displayed on the workshop website, but will NOT be included in the NAACL 2021
                    Workshop proceedings or otherwise archived.
                </p>

            </div>

        </div>
    </div>
    <!-- /.container -->
</div>
<!--
<div id ="proceedings" class="content-section-b">

    <div class="container">

        <div class="row">

            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading">Proceedings</h3>
                <li>TBD</li>
            </div>
        </div>
    </div>
</div>
-->

<div id ="accepted-papers" class="content-section-b">
    <div class="container">
        <div class="row">
            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading">Accepted Papers</h3>
                <h4 class="section-heading">Archival track:</h4>
                <ul>
                  <li>
                    <b> Feature-level Incongruence Reduction for Multimodal Translation </b>
                    <br>
                    Zhifeng Li, Yu Hong, Yuchen Pan, Jian Tang, Jianmin Yao and Guodong Zhou 
                  </li>
                  <li>
                    <b> Error Causal inference for Multi-Fusion models </b>
                    <br>
                    Chengxi Li and Brent Harrison 
                  </li>
                  <li>
                    <b> Leveraging Partial Dependency Trees to Control Image Captions </b>
                    <br>
                    Wenjie Zhong and Yusuke Miyao 
                  </li>
                  <li>
                    <b> Grounding Plural Phrases: Countering Evaluation Biases by Individuation </b>
                    <br>
                    Julia Suter, Letitia Parcalabescu and Anette Frank 
                  </li>
                  <li>
                    <b> PanGEA: The Panoramic Graph Environment Annotation Toolkit </b>
                    <br>
                    Alexander Ku, Peter Anderson, Jordi Pont Tuset and Jason Baldridge 
                  </li>
                  <li>
                    <b> Learning to Learn Semantic Factors in Heterogeneous Image Classification </b>
                    <br>
                    Boyue Fan and Zhenting Liu 
                  </li>
                  <li>
                    <b> Reference and coreference in situated dialogue </b>
                    <br>
                    Sharid LoÃ¡iciga, Simon Dobnik and David Schlangen 
                  </li>
                </ul>
                
                <h4 class="section-heading">Non-archival track:</h4>
               
                <ul>
                  <li>
                    <b> Interactive Learning from Activity Description </b>
                    <br>
                    Khanh Nguyen, Dipendra Misra, Robert Schapire, Miro Dudik and Patrick Shafto 
                  </li>
                  <li>
                    <b> Towards Multi-Modal Text-Image Retrieval to improve Human Reading </b>
                    <br>
                    Florian Schneider, Ãzge Alacam, Xintong Wang and Chris Biemann 
                  </li>
                  <li>
                    <b> Language-based Video Editing via Multi-Modal Multi-Level Transformer </b>
                    <br>
                    Tsu-Jui Fu, Xin Wang, Scott Grafton, Miguel Eckstein and William Yang Wang 
                  </li>
                  <li>
                    <b> Learning to Select Question-Relevant Relations for Visual Question Answering </b>
                    <br>
                    Hwanhee Lee, Jaewoong Lee, Heejoon Lee and Kyomin Jung 
                  </li>
                  <li>
                    <b> CLEVR_HYP: A Challenge Dataset and Baselines for Visual Question Answering with Hypothetical Actions over Images </b>
                    <br>
                    Shailaja Keyur Sampat, Akshay Kumar, Yezhou Yang and Chitta Baral 
                  </li>
                  <li>
                    <b> Multimodal Text Style Transfer for Outdoor Vision-and-Language Navigation </b>
                    <br>
                    Wanrong Zhu, Xin Wang, Tsu-Jui Fu, An Yan, Pradyumna Narayana, Kazoo Sone, Sugato Basu and William Yang Wang
                  </li>
                  <li>
                    <b> What is Multimodality?  </b>
                    <br>
                    Letitia Parcalabescu, Nils Trost and Anette Frank 
                  </li>
                  <li>
                    <b> Pathdreamer: A World Model for Indoor Navigation </b>
                    <br>
                    Jing Yu Koh, Honglak Lee, Yinfei Yang, Jason Baldridge and Peter Anderson 
                  </li>
                  <li>
                    <b> Visual Goal-Step Inference using wikiHow </b>
                    <br>
                    Yue Yang, Artemis Panagopoulou, Qing Lyu, Li Zhang, Mark Yatskar and Chris Callison-Burch 
                  </li>
                  <li>
                    <b> Neural Event Semantics for Grounded Language Understanding </b>
                    <br>
                    Shyamal Buch, Li Fei-Fei and Noah Goodman 
                  </li>
                </ul>
            </div>
        </div>
    </div>
</div>
    
<!-- Program -->
<div id ="program" class="content-section-b">

    <div class="container">
        <div class="row">
            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading">Program (PDT)</h3>
                <!--<p class="lead">
                    <b>ATTENTION! The video recording of the whole workshop is located at <a href="https://slideslive.com/38931798/w9-alvr-live-stream" style="color:orange"> <u>https://slideslive.com/38931798/w9-alvr-live-stream</u></a></b>. Some pre-recorded talks are listed below, while others are included in the workshop recording.
                </p>-->
            </div>

            <table class="table" style="width:100%">
                <tr>
                    <th>Time </th>
                    <th>Event </th>
                    <th>Who </th>
                    </th>

                <tr class="info">
                    <td>8:30-8:35</td>
                    <td><strong>Opening Remarks</strong></td>
                    <td>Workshop Organizers</td>
                </tr>

                <tr class="success">
                    <td>8:35-9:10</td>
                    <td><strong>Invited Speaker 1</strong><br />Invited Talk & QA</td>
                    <td>Yonatan Bisk</td>
                </tr>

                <tr class="success">
                    <td>9:10-9:45</td>
                    <td><strong>Invited Speaker 2</strong><br />Invited Talk & QA</td>
                    <td>William Wang</td>
                </tr>
                
                <tr class="info">
                    <td>9:45-10:10</td>
                    <td><strong>Poster Highlight</strong><br /></td>
                    <td></td>
                </tr>
            
                <tr>
                    <td>10:10-10:50</td>
                    <td><strong>Poster Session 1</strong><br /></td>
                    <td></td>
                </tr>

                <tr class="success">
                    <td>10:50-11:25</td>
                    <td><strong>Invited Speaker 3</strong><br />Invited Talk & QA</td>
                    <td>Jason Baldridge</td>
                </tr>

                <tr class="success">
                    <td>11:25-12:00</td>
                    <td><strong>Invited Speaker 4</strong><br />Invited Talk & QA</td>
                    <td>Joyce Chai</td>
                </tr>
            
                <tr class="info">
                    <td>12:00-12:30</td>
                    <td><strong>Panel Session 1</strong><br /></td>
                    <td>Jason Baldridge, Joyce Chai, Kate Saenko, William Wang</td>
                </tr>

                <tr>
                    <td>12:30-13:20</td>
                    <td><strong>Lunch</strong><br /></td>
                    <td></td>
                </tr>

                <tr class="success">
                    <td>13:20-13:55</td>
                    <td><strong>Invited Speaker 5</strong><br />Invited Talk & QA</td>
                    <td>Kate Saenko</td>
                </tr>

                <tr class="success">
                    <td>13:55-14:30</td>
                    <td><strong>Invited Speaker 6</strong><br />Invited Talk & QA</td>
                    <td>Jacob Andreas</td>
                </tr>

                <tr class="success">
                    <td>14:30-15:05</td>
                    <td><strong>Invited Speaker 7</strong><br />Invited Talk & QA</td>
                    <td>Yejin Choi</td>
                </tr>

                <tr>
                    <td>15:05-15:45</td>
                    <td><strong>Poster Session 2</strong><br /></td>
                    <td></td>
                </tr>

                <tr class="success">
                    <td>15:45-16:20</td>
                    <td><strong>Explanations for Visual Question Answering</strong><br />Invited Talk & QA</td>
                    <td>Ray Mooney</td>
                </tr>

                <tr class="success">
                    <td>16:20-16:55</td>
                    <td><strong>Invited Speaker 9</strong><br />Invited Talk & QA</td>
                    <td>Anja Rohrbach</td>
                </tr>

                <tr class="success">
                    <td>16:55-17:30</td>
                    <td><strong>Invited Speaker 10</strong><br />Invited Talk & QA</td>
                    <td>Mohit Bansal</td>
                </tr>

                <tr class="info">
                    <td>17:30-18:00</td>
                    <td><strong>Panel Session 2</strong><br /></td>
                    <td>Jacob Andreas, Mohit Bansal, Yejin Choi, Ray Mooney, Anja Rohrbach</td>
                </tr>

            </table>

            <div class="container">
                <div class="wow " data-animation-delay="200">
                </div>
            </div>
        </div>
    </div>
</div>


<!-- Invited Speakers -->
<div id ="invited" class="content-section-b">

    <div class="container">

        <div class="row">
            <div class="container">

                <div class="row wow "  data-animation-delay="200">
                    <h3 class="section-heading">Invited Speakers</h3>
                    <!--<p>(presentation order)</p>-->
                    <br>
                </div>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/jacob.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://www.mit.edu/~jda/" target="blank">Jacob Andreas</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Jacob Andreas is the X Consortium Career Development Assistant Professor at MIT. His research focuses on building intelligent systems that can communicate effectively using language and learn from human guidance. Jacob earned his Ph.D. from UC Berkeley, his M.Phil. from Cambridge (where he studied as a Churchill scholar) and his B.S. from Columbia. He has been the recipient of an NSF graduate fellowship, a Facebook fellowship, and paper awards at NAACL and ICML.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/jason.jpeg" alt=""></center>
                        <h4 class="section-heading"><center><a href="http://www.jasonbaldridge.com/" target="blank">Jason Baldridge</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Jason is a research scientist at Google, where he works on natural language understanding. He was previously an Associate Professor of Computational Linguistics at the University of Texas at Austin. His main research interests include categorial grammars, parsing, semi-supervised learning for NLP, reference resolution and text geolocation. He has long been active in the creation and promotion of open source software for natural language processing, including co-creating the Apache OpenNLP Toolkit and OpenCCG. Jason received his Ph.D. from the University of Edinburgh in 2002, where his doctoral dissertation on Multimodal Combinatory Categorial Grammar was awarded the 2003 Beth Dissertation Prize from the European Association for Logic, Language and Information.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/mohit.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://www.cs.unc.edu/~mbansal/" target="blank">Mohit Bansal</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Dr. Mohit Bansal is the John R. & Louise S. Parker Associate Professor and the Director of the MURGe-Lab (UNC-NLP Group) in the Computer Science department at University of North Carolina (UNC) Chapel Hill. He received his PhD from UC Berkeley in 2013 (where he was advised by Dan Klein) and his BTech from IIT Kanpur in 2008. His research expertise is in statistical natural language processing and machine learning, with a particular focus on multimodal, grounded, and embodied semantics (i.e., language with vision and speech, for robotics), human-like language generation and Q&A/dialogue, and interpretable and generalizable deep learning.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/yonatan.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://yonatanbisk.com/" target="blank">Yonatan Bisk</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Yonatan Bisk is an Assistant Professor at Carnegie Mellon University. Yonatanâs research area is Natural Language Processing (NLP) with a focus on grounding. In particular, his work broadly falls into: 1. Uncovering the latent structures of natural language, 2. Modeling the semantics of the physical world, and 3. Connecting language to perception and control.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/joyce.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://web.eecs.umich.edu/~chaijy/" target="blank">Joyce Y. Chai</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Joyce Y. Chai is a Professor at University of Michigan. Her research interests are in the area of artificial intelligence, particularly on natural language processing, situated dialogue agents, human-robot communication, and intelligent user interfaces. Her recent work has focused on grounded language processing to facilitate situated communication with robots and other artificial agents. Prior to joining UM, she was a professor at MSU directing the Language and Interaction Research Lab . At UM, she is a member of Michigan AI Lab and directing the Situated Language and Embodied Dialogue (SLED) research group. She is also affiliated with Michigan Robotics Institute.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/yejin.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://homes.cs.washington.edu/~yejin/" target="blank">Yejin Choi</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Yejin Choi is an associate professor of Paul G. Allen School of Computer Science & Engineering at the University of Washington with the Brett Helsel Career Development Professorship, adjunct of the Linguistics department, and affiliate of the Center for Statistics and Social Sciences. She is also a senior research manager at the Allen Institute for Artificial Intelligence overseeing the project Mosaic on Commonsense Intelligence. She is a co-recepient of the AAAI Outstanding Paper Award in 2020, the Marr Prize (best paper award) at ICCV 2013, a recepient of Borg Early Career Award (BECA) in 2018, and named among IEEE AI's 10 to Watch in 2016.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/raymond.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://www.cs.utexas.edu/~mooney/" target="blank">Raymond J. Mooney</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Raymond J. Mooney is a Professor in the Department of Computer Science at the University of Texas at Austin. He received his Ph.D. in 1988 from the University of Illinois at Urbana/Champaign. He is an author of over 160 published research papers, primarily in the areas of machine learning and natural language processing. He was the President of the International Machine Learning Society from 2008-2011, program co-chair for AAAI 2006, general chair for HLT-EMNLP 2005, and co-chair for ICML 1990. He is a Fellow of the American Association for Artificial Intelligence, the Association for Computing Machinery, and the Association for Computational Linguistics and the recipient of best paper awards from AAAI-96, KDD-04, ICML-05 and ACL-07.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/anna.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://anna-rohrbach.net/" target="blank">Anja Rohrbach</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Anja Rohrbach is a Research Scientist at UC Berkeley, working with Prof. Trevor Darrell. She has completed her PhD at Max Planck Institute for Informatics under supervision of Prof. Bernt Schiele. Her research is at the intersection of vision and language. She is interested in a variety of tasks, including image and video description, visual grounding, visual question answering, etc. Recently, she is focusing on building explainable models and addressing bias in existing vision and language models.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/kate.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="http://ai.bu.edu/ksaenko.html" target="blank">Kate Saenko</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>Kate is an Associate Professor of Computer Science at Boston University and a consulting professor for the MIT-IBM Watson AI Lab. She leads the Computer Vision and Learning Group at BU, is the founder and co-director of the Artificial Intelligence Research (AIR) initiative, and member of the Image and Video Computing research group. Kate received a PhD from MIT and did her postdoctoral training at UC Berkeley and Harvard. Her research interests are in the broad area of Artificial Intelligence with a focus on dataset bias, adaptive machine learning, learning for image and language understanding, and deep learning.</p>
                    </div>
                </div>
                <p></p>

                <div class="row wow "  data-animation-delay="200">
                    <div class="col-sm-3 wow"  data-animation-delay="200">
                        <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/invited/william.jpg" alt=""></center>
                        <h4 class="section-heading"><center><a href="https://sites.cs.ucsb.edu/~william/" target="blank">William Wang</a></center></h4>
                    </div>
                    <div class="col-sm-8 col-md-offset-1 wow" style="text-align:justify" data-animation-delay="200">
                        <p>William Wang is the Director of UC Santa Barbara's Natural Language Processing group and Center for Responsible Machine Learning. He is the Duncan and Suzanne Mellichamp Chair in Artificial Intelligence and Designs, and an Assistant Professor in the Department of Computer Science at the University of California, Santa Barbara. He received his PhD from School of Computer Science, Carnegie Mellon University. He has broad interests in machine learning approaches to data science, including statistical relational learning, information extraction, computational social science, speech, and vision.</p>
                    </div>
                </div>
                <p></p>

            </div>
        </div>
    </div>
</div>

<!-- Organizers -->
<div id="organizers" class="content-section-b">

    <div class="container">
        <div class="row wow "  data-animation-delay="200">
            <h3 class="section-heading">Organizers</h3>

            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/xin.jpg" alt=""></center>
                <h4 class="section-heading"><center><a href="https://eric-xw.github.io/">Xin (Eric) Wang</a></center></h4>
                <h5 class="section-heading"><center><i>UC Santa Cruz</i></center></h5>
            </div>

            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/ronghang.png" alt=""></center>
                <h4 class="section-heading"><center><a href="http://ronghanghu.com/">Ronghang Hu</a></center></h4>
                <h5 class="section-heading"><center><i>Facebook AI Research</i></center></h5>
            </div>

            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/drew.jpg" alt=""></center>
                <h4 class="section-heading"><center><a href="https://scholar.google.com/citations?user=q_trRV0AAAAJ">Drew Hudson</a></center></h4>
                <h5 class="section-heading"><center><i>Stanford</i></center></h5>
            </div>

            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/ray.jpg" alt=""></center>
                <h4 class="section-heading"><center><a href="https://tsujuifu.github.io/">Tsu-Jui Fu</a></center></h4>
                <h5 class="section-heading"><center><i>UC Santa Barbara</i></center></h5>
            </div>
            <!-- </div> -->

            <!-- <div class="row wow "  data-animation-delay="200"> -->
            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/marcus.jpg" alt=""></center>
                <h4 class="section-heading"><center><a href="https://rohrbach.vision/">Marcus Rohrbach</a></center></h4>
                <h5 class="section-heading"><center><i>Facebook AI Research</i></center></h5>
            </div>

            <div class="col-sm-2 wow "  data-animation-delay="200">
                <center><img  class="img-responsive img-rounded" style="border-radius: 50%" height="150" width="150" src="img/organizer/daniel.jpg" alt=""></center>
                <h4 class="section-heading"><center><a href="http://people.eecs.berkeley.edu/~dfried/">Daniel Fried</a></center></h4>
                <h5 class="section-heading"><center><i>UC Berkeley</i></center></h5>
            </div>
        </div>
        <div class="wow " data-animation-delay="200">
          <h3 class="section-heading" style="color:white">Contact</h3>
          <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
          <p class="lead"  style="text-align:left;color:white">
          Contact the Organizing Committee: alvr2021_naacl2021@softconf.com
          </p>

    </div>
    </div>
</div>

<!-- Program Committee -->

<div id ="committee" class="content-section-b" style="border-top: 0">
    <div class="container">
        <div class="row">

            <div class="col-sm-6 pull-right wow ">
                <img class="img-responsive " src="img/ipad.png" alt="">
            </div>

            <div class="wow " data-animation-delay="200">
                <h3 class="section-heading"> Program Committee</h3>

                <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
                <table cellspacing="0" cellpadding="0" style="margin-left: auto;margin-right: auto;width:75%">
                    <tr><td><li>Shubham Agarwal</td><td>Heriot-Watt University</td></li><td></td></tr>
                    <tr><td><li>Arjun Akula</td><td>University of California, Los Angeles</td></li><td></td></tr>
                    <tr><td><li>Asma Ben Abacha</td><td>NIH/NLM</td></li><td></td></tr>
                    <tr><td><li>Luciana Benotti</td><td>Universidad Nacional de CÃ³rdoba</td></li><td></td></tr>
                    <tr><td><li>Khyathi Raghavi Chandu</td><td>Carnegie Mellon University</td></li><td></td></tr>
                    <tr><td><li>Angel Chang</td><td>Stanford University</td></li><td></td></tr>
                    <tr><td><li>Dhivya Chinnappa</td><td>Thomson Reuters</td></li><td></td></tr>
                    <tr><td><li>Abhishek Das</td><td>Facebook AI</td></li><td></td></tr>
                    <tr><td><li>Simon Dobnik</td><td>University of Gothenburg</td></li><td></td></tr>
                    <tr><td><li>Thoudam Doren Singh</td><td>National Institute of Technology, Silchar, India</td></li><td></td></tr>
                    <tr><td><li>Hamed Firooz</td><td>Facebook AI</td></li><td></td></tr>
                    <tr><td><li>Zhe Gan</td><td>Microsoft</td></li><td></td></tr>
                    <tr><td><li>Cristina Garbacea</td><td>University of Michigan</td></li><td></td></tr>
                    <tr><td><li>Jack Hessel</td><td>AI2</td></li><td></td></tr>
                    <tr><td><li>Gabriel Ilharco</td><td>University of Washington</td></li><td></td></tr>
                    <tr><td><li>Shailza Jolly</td><td>TU Kaiserslautern Germany</td></li><td></td></tr>
                    <tr><td><li>Marimuthu Kalimuthu</td><td>Saarland University, Saarland Informatics Campus</td></li><td></td></tr>
                    <tr><td><li>Noriyuki Kojima</td><td>Cornell University</td></li><td></td></tr>
                    <tr><td><li>Christopher KÃ¼mmel</td><td>Beuth University of Applied Sciences Berlin</td></li><td></td></tr>
                    <tr><td><li>Loitongbam Sanayai Meetei</td><td>National Institute of Technology Silchar, India</td></li><td></td></tr>
                    <tr><td><li>Khanh Nguyen</td><td>University of Maryland</td></li><td></td></tr>
                    <tr><td><li>Yulei Niu</td><td>Renmin University of China</td></li><td></td></tr>
                    <tr><td><li>Aishwarya Padmakumar</td><td>University of Texas, Austin</td></li><td></td></tr>
                    <tr><td><li>Hamid Palangi</td><td>Microsoft Research</td></li><td></td></tr>
                    <tr><td><li>Shruti Palaskar</td><td>Carnegie Mellon University</td></li><td></td></tr>
                    <tr><td><li>Vikas Raunak</td><td>Carnegie Mellon University</td></li><td></td></tr>
                    <tr><td><li>Arka Sadhu</td><td>University of Southern California</td></li><td></td></tr>
                    <tr><td><li>Alok Singh</td><td>National Institute of Technology, Silchar India</td></li><td></td></tr>
                    <tr><td><li>Alane Suhr</td><td>Cornell University</td></li><td></td></tr>
                    <tr><td><li>Hao Tan</td><td>University of North Carolina</td></li><td></td></tr>
                    <tr><td><li>Xiangru Tang</td><td>University of the Chinese Academy of Sciences, China</td></li><td></td></tr>
                    <tr><td><li>Ece Takmaz</td><td>University of Amsterdam</td></li><td></td></tr>
                </table>
                <br/>

                <!--p><a class="btn btn-embossed btn-primary" href="#" role="button">View Details</a>
                <a class="btn btn-embossed btn-info" href="#" role="button">Visit Website</a></p-->
            </div>
        </div>
    </div>

    <!-- /.container -->


    <!-- Sponsor -->
    <!-- <div id ="sponsors" class="content-section-a" style="border-top: 0"> -->
    <!-- <div class="container">			 -->
    <!-- <div class="row">			 -->
    <!--div class="col-sm-6 pull-right wow ">
        <img class="img-responsive " src="img/ipad.png" alt="">
    </div-->
    <!-- <div class="wow " data-animation-delay="200">    -->
    <!-- <h3 class="section-heading"> Sponsor </h3> -->
    <!--div class="sub-title lead3">Lorem ipsum dolor sit atmet sit dolor greand fdanrh<br> sdfs sit atmet sit dolor greand fdanrh sdfs</div-->
    <!-- <p class="lead"  style="text-align:justify"> -->
    <!-- <a href=" " target="_blank"><img src="img/sponsor/XXX.png" width="300"></a> -->
    <!-- </p> -->
    <!--p><a class="btn btn-embossed btn-primary" href="#" role="button">View Details</a>
    <a class="btn btn-embossed btn-info" href="#" role="button">Visit Website</a></p-->
    <!-- </div>    -->
    <!-- </div> -->
    <!-- </div> -->
    <!-- /.container -->
    <!-- </div> -->

    <!--
    <div id="contacts" class="content-section-c ">
        <div class="container">
            <div class="row">

                <div class="wow " data-animation-delay="200">
                    <h3 class="section-heading" style="color:white">Contact</h3>
                    <p class="lead"  style="text-align:left;color:white">
                        Contact the Organizing Committee: alvr2021_naacl2021@softconf.com
                    </p>

                </div>
            </div>
            <div class="row">

                <div class="col-md-6 col-md-offset-3 text-center">
                    <div >
                        <div class="morph-button ">
                            <button type="button"></button>

                        </div>
                    </div>
                </div>
            </div>

        </div>
    </div>
    -->

    <footer>

    </footer>

    <!-- JavaScript -->
    <script src="js/jquery-1.10.2.js"></script>
    <script src="js/bootstrap.js"></script>
    <script src="js/owl.carousel.js"></script>
    <script src="js/script.js"></script>
    <!-- StikyMenu -->
    <script src="js/stickUp.min.js"></script>
    <script type="text/javascript">
      jQuery(function($) {
        $(document).ready( function() {
          $('.navbar-default').stickUp();

        });
      });

    </script>
    <!-- Smoothscroll -->
    <script type="text/javascript" src="js/jquery.corner.js"></script>
    <script src="js/wow.min.js"></script>
    <script>
      new WOW().init();
    </script>
    <script src="js/classie.js"></script>
    <script src="js/uiMorphingButton_inflow.js"></script>
    <!-- Magnific Popup core JS file -->
    <script src="js/jquery.magnific-popup.js"></script>
</body>

</html>
